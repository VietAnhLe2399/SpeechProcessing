{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "#     for f in files:\n",
    "#         print(f)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tôi dataset\n",
      "Load nhà dataset\n",
      "Load học dataset\n",
      "Load nhân viên dataset\n",
      "Load hà nội dataset\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class_names = ['tôi', 'nhà', 'học', 'nhân viên', 'hà nội']\n",
    "dataset = {}\n",
    "dataset_train = {}\n",
    "dataset_test = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"wav_file\", cname))\n",
    "#     uncomment to shuffle dataset\n",
    "    random.shuffle(dataset[cname])\n",
    "    train_size = int(0.8*len(dataset[cname]))\n",
    "    dataset_train[cname] = dataset[cname][:train_size]\n",
    "    dataset_test[cname] = dataset[cname][train_size:]\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "# print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "# Comment KMEANS for GMMHMM\n",
    "# kmeans = clustering(all_vectors)\n",
    "# print(\"centers\", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -210652.5281             +nan\n",
      "         2     -201616.8623       +9035.6658\n",
      "         3     -198649.9633       +2966.8990\n",
      "         4     -198048.6827        +601.2807\n",
      "         5     -197860.5356        +188.1471\n",
      "         6     -197748.0645        +112.4711\n",
      "         7     -197661.1619         +86.9026\n",
      "         8     -197543.1840        +117.9779\n",
      "         9     -197503.4112         +39.7728\n",
      "        10     -197444.4287         +58.9825\n",
      "        11     -197407.6647         +36.7640\n",
      "        12     -197352.6349         +55.0298\n",
      "        13     -197273.5756         +79.0593\n",
      "        14     -197194.1059         +79.4697\n",
      "        15     -197142.8571         +51.2488\n",
      "        16     -197109.8490         +33.0081\n",
      "        17     -197083.7898         +26.0593\n",
      "        18     -197060.8647         +22.9251\n",
      "        19     -196945.0738        +115.7909\n",
      "        20     -196825.8477        +119.2261\n",
      "        21     -196762.4697         +63.3780\n",
      "        22     -196727.9571         +34.5126\n",
      "        23     -196697.7409         +30.2162\n",
      "        24     -196677.9236         +19.8174\n",
      "        25     -196669.0927          +8.8308\n",
      "        26     -196663.4929          +5.5999\n",
      "        27     -196653.4847         +10.0081\n",
      "        28     -196634.6688         +18.8160\n",
      "        29     -196615.5665         +19.1023\n",
      "        30     -196599.7416         +15.8249\n",
      "        31     -196575.6746         +24.0670\n",
      "        32     -196544.2085         +31.4661\n",
      "        33     -196475.7954         +68.4132\n",
      "        34     -196464.7538         +11.0415\n",
      "        35     -196462.2863          +2.4676\n",
      "        36     -196459.8341          +2.4522\n",
      "        37     -196456.2300          +3.6041\n",
      "        38     -196451.1874          +5.0425\n",
      "        39     -196447.6167          +3.5707\n",
      "        40     -196446.1113          +1.5054\n",
      "        41     -196445.2874          +0.8239\n",
      "        42     -196444.5475          +0.7399\n",
      "        43     -196443.6599          +0.8876\n",
      "        44     -196442.4028          +1.2571\n",
      "        45     -196441.0784          +1.3244\n",
      "        46     -196440.2727          +0.8057\n",
      "        47     -196439.7709          +0.5017\n",
      "        48     -196439.4121          +0.3588\n",
      "        49     -196439.1132          +0.2989\n",
      "        50     -196438.8126          +0.3005\n",
      "        51     -196438.4601          +0.3526\n",
      "        52     -196438.0363          +0.4238\n",
      "        53     -196437.5104          +0.5259\n",
      "        54     -196436.6397          +0.8707\n",
      "        55     -196435.4215          +1.2182\n",
      "        56     -196434.3026          +1.1189\n",
      "        57     -196433.3816          +0.9210\n",
      "        58     -196432.4022          +0.9794\n",
      "        59     -196431.0497          +1.3526\n",
      "        60     -196429.3855          +1.6642\n",
      "        61     -196428.3254          +1.0601\n",
      "        62     -196427.8861          +0.4393\n",
      "        63     -196427.5943          +0.2918\n",
      "        64     -196427.3321          +0.2622\n",
      "        65     -196427.0470          +0.2850\n",
      "        66     -196426.6865          +0.3605\n",
      "        67     -196426.2360          +0.4505\n",
      "        68     -196425.8105          +0.4255\n",
      "        69     -196425.5167          +0.2938\n",
      "        70     -196425.3017          +0.2150\n",
      "        71     -196425.0725          +0.2292\n",
      "        72     -196424.7619          +0.3107\n",
      "        73     -196424.4151          +0.3468\n",
      "        74     -196424.1391          +0.2760\n",
      "        75     -196423.9026          +0.2365\n",
      "        76     -196423.6633          +0.2392\n",
      "        77     -196423.3953          +0.2680\n",
      "        78     -196423.0630          +0.3324\n",
      "        79     -196422.5805          +0.4825\n",
      "        80     -196421.6890          +0.8915\n",
      "        81     -196420.7083          +0.9807\n",
      "        82     -196420.1398          +0.5685\n",
      "        83     -196419.1142          +1.0255\n",
      "        84     -196414.9352          +4.1791\n",
      "        85     -196405.2147          +9.7205\n",
      "        86     -196396.5490          +8.6657\n",
      "        87     -196367.3014         +29.2476\n",
      "        88     -196346.3881         +20.9133\n",
      "        89     -196338.2799          +8.1082\n",
      "        90     -196333.6543          +4.6256\n",
      "        91     -196330.6092          +3.0451\n",
      "        92     -196328.2717          +2.3375\n",
      "        93     -196326.1831          +2.0886\n",
      "        94     -196324.1490          +2.0340\n",
      "        95     -196322.5458          +1.6032\n",
      "        96     -196321.5412          +1.0046\n",
      "        97     -196321.0267          +0.5145\n",
      "        98     -196320.3617          +0.6650\n",
      "        99     -196318.9542          +1.4075\n",
      "       100     -196316.3701          +2.5841\n",
      "       101     -196314.5117          +1.8584\n",
      "       102     -196313.5200          +0.9917\n",
      "       103     -196312.8886          +0.6313\n",
      "       104     -196312.4943          +0.3943\n",
      "       105     -196312.2395          +0.2548\n",
      "       106     -196312.0626          +0.1769\n",
      "       107     -196311.9336          +0.1290\n",
      "       108     -196311.8375          +0.0961\n",
      "       109     -196311.7659          +0.0716\n",
      "       110     -196311.7133          +0.0526\n",
      "       111     -196311.6754          +0.0379\n",
      "       112     -196311.6484          +0.0270\n",
      "       113     -196311.6294          +0.0190\n",
      "       114     -196311.6160          +0.0135\n",
      "       115     -196311.6064          +0.0096\n",
      "         1     -244162.2393             +nan\n",
      "         2     -231277.4545      +12884.7848\n",
      "         3     -228773.3395       +2504.1151\n",
      "         4     -228046.2502        +727.0893\n",
      "         5     -227289.9816        +756.2685\n",
      "         6     -185046.1342      +42243.8475\n",
      "         7     -184853.2751        +192.8591\n",
      "         8     -184754.3667         +98.9084\n",
      "         9     -184720.1168         +34.2498\n",
      "        10     -184701.2224         +18.8944\n",
      "        11     -184678.3168         +22.9056\n",
      "        12     -184654.3167         +24.0001\n",
      "        13     -184632.4675         +21.8492\n",
      "        14     -184612.2307         +20.2368\n",
      "        15     -184582.4941         +29.7366\n",
      "        16     -184529.9688         +52.5253\n",
      "        17     -184490.9925         +38.9763\n",
      "        18     -184467.8029         +23.1896\n",
      "        19     -184448.4046         +19.3983\n",
      "        20     -184429.0869         +19.3177\n",
      "        21     -184410.2026         +18.8843\n",
      "        22     -184398.1728         +12.0298\n",
      "        23     -184380.2854         +17.8874\n",
      "        24     -184369.6390         +10.6464\n",
      "        25     -184362.4226          +7.2164\n",
      "        26     -184357.2544          +5.1682\n",
      "        27     -184353.6859          +3.5685\n",
      "        28     -184349.6876          +3.9983\n",
      "        29     -184334.4227         +15.2648\n",
      "        30     -184331.1806          +3.2421\n",
      "        31     -184329.5274          +1.6532\n",
      "        32     -184328.5246          +1.0027\n",
      "        33     -184327.7824          +0.7423\n",
      "        34     -184327.2168          +0.5655\n",
      "        35     -184326.7879          +0.4290\n",
      "        36     -184326.4563          +0.3315\n",
      "        37     -184326.1937          +0.2627\n",
      "        38     -184325.9846          +0.2091\n",
      "        39     -184325.8222          +0.1624\n",
      "        40     -184325.7003          +0.1219\n",
      "        41     -184325.6089          +0.0914\n",
      "        42     -184325.5379          +0.0710\n",
      "        43     -184325.4802          +0.0577\n",
      "        44     -184325.4317          +0.0484\n",
      "        45     -184325.3905          +0.0412\n",
      "        46     -184325.3552          +0.0353\n",
      "        47     -184325.3248          +0.0304\n",
      "        48     -184325.2985          +0.0263\n",
      "        49     -184325.2753          +0.0232\n",
      "        50     -184325.2544          +0.0209\n",
      "        51     -184325.2351          +0.0194\n",
      "        52     -184325.2168          +0.0182\n",
      "        53     -184325.1998          +0.0170\n",
      "        54     -184325.1844          +0.0154\n",
      "        55     -184325.1712          +0.0132\n",
      "        56     -184325.1606          +0.0105\n",
      "        57     -184325.1528          +0.0079\n",
      "         1     -191581.0648             +nan\n",
      "         2     -184557.4844       +7023.5804\n",
      "         3     -182144.5485       +2412.9359\n",
      "         4     -181507.4050        +637.1435\n",
      "         5     -181172.8768        +334.5282\n",
      "         6     -180999.2160        +173.6608\n",
      "         7     -180849.4146        +149.8015\n",
      "         8     -180729.8135        +119.6010\n",
      "         9     -180662.0415         +67.7721\n",
      "        10     -180615.2532         +46.7883\n",
      "        11     -180591.4279         +23.8252\n",
      "        12     -180565.0774         +26.3506\n",
      "        13     -180541.2836         +23.7937\n",
      "        14     -180526.2011         +15.0826\n",
      "        15     -180513.7748         +12.4263\n",
      "        16     -180503.7982          +9.9766\n",
      "        17     -180494.4237          +9.3744\n",
      "        18     -180482.0316         +12.3921\n",
      "        19     -180471.3252         +10.7064\n",
      "        20     -180462.7829          +8.5423\n",
      "        21     -180450.4312         +12.3517\n",
      "        22     -180443.3483          +7.0829\n",
      "        23     -180436.5386          +6.8097\n",
      "        24     -180423.3985         +13.1401\n",
      "        25     -180408.1758         +15.2227\n",
      "        26     -180403.2896          +4.8862\n",
      "        27     -180398.8710          +4.4187\n",
      "        28     -180392.7484          +6.1226\n",
      "        29     -180380.6893         +12.0591\n",
      "        30     -180375.0328          +5.6565\n",
      "        31     -180363.3402         +11.6926\n",
      "        32     -180358.9121          +4.4280\n",
      "        33     -180352.4924          +6.4197\n",
      "        34     -180342.7458          +9.7466\n",
      "        35     -180330.7267         +12.0191\n",
      "        36     -180328.2497          +2.4771\n",
      "        37     -180324.6280          +3.6217\n",
      "        38     -180314.0940         +10.5340\n",
      "        39     -180300.5904         +13.5036\n",
      "        40     -180298.4596          +2.1308\n",
      "        41     -180296.2751          +2.1845\n",
      "        42     -180294.6107          +1.6644\n",
      "        43     -180293.4381          +1.1726\n",
      "        44     -180291.0062          +2.4319\n",
      "        45     -180289.5440          +1.4623\n",
      "        46     -180289.2916          +0.2524\n",
      "        47     -180289.0805          +0.2111\n",
      "        48     -180288.8744          +0.2061\n",
      "        49     -180288.6551          +0.2193\n",
      "        50     -180288.4110          +0.2441\n",
      "        51     -180288.1344          +0.2765\n",
      "        52     -180287.8172          +0.3172\n",
      "        53     -180287.4238          +0.3934\n",
      "        54     -180286.7951          +0.6287\n",
      "        55     -180285.5996          +1.1955\n",
      "        56     -180284.3546          +1.2450\n",
      "        57     -180283.5308          +0.8238\n",
      "        58     -180282.6994          +0.8314\n",
      "        59     -180281.4633          +1.2361\n",
      "        60     -180279.1321          +2.3311\n",
      "        61     -180276.0431          +3.0890\n",
      "        62     -180273.0448          +2.9983\n",
      "        63     -180268.0109          +5.0339\n",
      "        64     -180261.8965          +6.1145\n",
      "        65     -180257.2460          +4.6505\n",
      "        66     -180254.5771          +2.6689\n",
      "        67     -180250.4122          +4.1649\n",
      "        68     -180248.3034          +2.1088\n",
      "        69     -180247.2891          +1.0143\n",
      "        70     -180245.7274          +1.5617\n",
      "        71     -180241.6466          +4.0808\n",
      "        72     -180237.8535          +3.7931\n",
      "        73     -180235.4165          +2.4370\n",
      "        74     -180230.1801          +5.2364\n",
      "        75     -180224.8705          +5.3096\n",
      "        76     -180220.2083          +4.6622\n",
      "        77     -180218.3146          +1.8937\n",
      "        78     -180218.0605          +0.2541\n",
      "        79     -180217.9305          +0.1299\n",
      "        80     -180217.8094          +0.1211\n",
      "        81     -180217.6770          +0.1324\n",
      "        82     -180217.5367          +0.1404\n",
      "        83     -180217.4040          +0.1327\n",
      "        84     -180217.2938          +0.1101\n",
      "        85     -180217.2127          +0.0811\n",
      "        86     -180217.1585          +0.0542\n",
      "        87     -180217.1240          +0.0344\n",
      "        88     -180217.1016          +0.0224\n",
      "        89     -180217.0857          +0.0159\n",
      "        90     -180217.0731          +0.0126\n",
      "        91     -180217.0623          +0.0108\n",
      "        92     -180217.0524          +0.0098\n",
      "         1     -355068.5490             +nan\n",
      "         2     -342184.1039      +12884.4451\n",
      "         3     -338714.2766       +3469.8273\n",
      "         4     -337539.5511       +1174.7255\n",
      "         5     -336888.2737        +651.2775\n",
      "         6     -336538.4373        +349.8363\n",
      "         7     -336353.8002        +184.6372\n",
      "         8     -336211.6620        +142.1382\n",
      "         9     -336106.9051        +104.7569\n",
      "        10     -336036.3385         +70.5666\n",
      "        11     -335985.3906         +50.9478\n",
      "        12     -335953.1252         +32.2654\n",
      "        13     -335910.5836         +42.5417\n",
      "        14     -335879.5649         +31.0187\n",
      "        15     -335853.2089         +26.3559\n",
      "        16     -335829.3790         +23.8300\n",
      "        17     -335799.3776         +30.0013\n",
      "        18     -335777.1743         +22.2034\n",
      "        19     -335761.0746         +16.0996\n",
      "        20     -335745.7779         +15.2967\n",
      "        21     -335730.2058         +15.5721\n",
      "        22     -335711.4334         +18.7724\n",
      "        23     -335677.8754         +33.5580\n",
      "        24     -335644.3213         +33.5541\n",
      "        25     -335623.3632         +20.9581\n",
      "        26     -335602.6249         +20.7383\n",
      "        27     -335583.4376         +19.1874\n",
      "        28     -335570.5824         +12.8552\n",
      "        29     -335557.7235         +12.8589\n",
      "        30     -335542.9151         +14.8084\n",
      "        31     -335530.6169         +12.2982\n",
      "        32     -335520.6919          +9.9250\n",
      "        33     -335511.8288          +8.8630\n",
      "        34     -335504.3378          +7.4910\n",
      "        35     -335498.5080          +5.8299\n",
      "        36     -335492.9798          +5.5281\n",
      "        37     -335485.9698          +7.0100\n",
      "        38     -335482.4019          +3.5679\n",
      "        39     -335479.7993          +2.6026\n",
      "        40     -335477.7151          +2.0843\n",
      "        41     -335476.2081          +1.5069\n",
      "        42     -335475.0164          +1.1917\n",
      "        43     -335474.0111          +1.0053\n",
      "        44     -335473.2265          +0.7846\n",
      "        45     -335472.6811          +0.5454\n",
      "        46     -335472.3063          +0.3747\n",
      "        47     -335472.0269          +0.2795\n",
      "        48     -335471.7993          +0.2276\n",
      "        49     -335471.6008          +0.1985\n",
      "        50     -335471.4180          +0.1828\n",
      "        51     -335471.2428          +0.1752\n",
      "        52     -335471.0710          +0.1719\n",
      "        53     -335470.9018          +0.1692\n",
      "        54     -335470.7386          +0.1632\n",
      "        55     -335470.5879          +0.1507\n",
      "        56     -335470.4567          +0.1312\n",
      "        57     -335470.3497          +0.1070\n",
      "        58     -335470.2674          +0.0823\n",
      "        59     -335470.2070          +0.0604\n",
      "        60     -335470.1641          +0.0430\n",
      "        61     -335470.1340          +0.0301\n",
      "        62     -335470.1130          +0.0210\n",
      "        63     -335470.0980          +0.0150\n",
      "        64     -335470.0868          +0.0112\n",
      "        65     -335470.0777          +0.0091\n",
      "         1     -375583.1730             +nan\n",
      "         2     -362107.5241      +13475.6488\n",
      "         3     -358759.0210       +3348.5031\n",
      "         4     -357717.0385       +1041.9825\n",
      "         5     -357012.9948        +704.0437\n",
      "         6     -356539.7256        +473.2692\n",
      "         7     -356193.5989        +346.1267\n",
      "         8     -355880.6870        +312.9119\n",
      "         9     -355627.9140        +252.7730\n",
      "        10     -355422.2914        +205.6226\n",
      "        11     -355338.8609         +83.4306\n",
      "        12     -355272.3081         +66.5528\n",
      "        13     -355205.5409         +66.7672\n",
      "        14     -355098.9866        +106.5543\n",
      "        15     -354945.6063        +153.3803\n",
      "        16     -354766.0587        +179.5476\n",
      "        17     -354625.9161        +140.1426\n",
      "        18     -354518.6266        +107.2895\n",
      "        19     -354428.4734         +90.1531\n",
      "        20     -354360.1470         +68.3265\n",
      "        21     -354295.4092         +64.7378\n",
      "        22     -354176.6394        +118.7697\n",
      "        23     -354105.5079         +71.1315\n",
      "        24     -354057.7801         +47.7279\n",
      "        25     -354032.4129         +25.3671\n",
      "        26     -354016.3091         +16.1039\n",
      "        27     -354003.8488         +12.4602\n",
      "        28     -353995.4158          +8.4330\n",
      "        29     -353988.7869          +6.6289\n",
      "        30     -353980.6897          +8.0972\n",
      "        31     -353971.4663          +9.2235\n",
      "        32     -353962.5520          +8.9142\n",
      "        33     -353957.3017          +5.2504\n",
      "        34     -353954.5055          +2.7962\n",
      "        35     -353952.6246          +1.8808\n",
      "        36     -353949.8932          +2.7315\n",
      "        37     -353947.4763          +2.4169\n",
      "        38     -353946.2278          +1.2484\n",
      "        39     -353945.2647          +0.9631\n",
      "        40     -353944.3404          +0.9243\n",
      "        41     -353943.3405          +1.0000\n",
      "        42     -353942.0183          +1.3222\n",
      "        43     -353940.1783          +1.8399\n",
      "        44     -353938.2303          +1.9480\n",
      "        45     -353936.1767          +2.0537\n",
      "        46     -353933.8578          +2.3189\n",
      "        47     -353931.5929          +2.2649\n",
      "        48     -353929.7351          +1.8578\n",
      "        49     -353928.0684          +1.6667\n",
      "        50     -353926.7411          +1.3273\n",
      "        51     -353925.7516          +0.9894\n",
      "        52     -353924.2407          +1.5109\n",
      "        53     -353918.4287          +5.8121\n",
      "        54     -353906.1753         +12.2533\n",
      "        55     -353898.9027          +7.2726\n",
      "        56     -353895.3394          +3.5633\n",
      "        57     -353892.0063          +3.3331\n",
      "        58     -353878.1299         +13.8765\n",
      "        59     -353854.1550         +23.9749\n",
      "        60     -353846.6892          +7.4658\n",
      "        61     -353832.6929         +13.9963\n",
      "        62     -353818.6751         +14.0177\n",
      "        63     -353805.9131         +12.7621\n",
      "        64     -353794.4979         +11.4152\n",
      "        65     -353784.5418          +9.9561\n",
      "        66     -353778.8089          +5.7330\n",
      "        67     -353776.3817          +2.4272\n",
      "        68     -353774.9360          +1.4457\n",
      "        69     -353772.1923          +2.7437\n",
      "        70     -353767.4904          +4.7019\n",
      "        71     -353764.1215          +3.3688\n",
      "        72     -353762.4099          +1.7116\n",
      "        73     -353761.5540          +0.8559\n",
      "        74     -353760.9299          +0.6241\n",
      "        75     -353760.4422          +0.4877\n",
      "        76     -353760.2000          +0.2421\n",
      "        77     -353760.1115          +0.0885\n",
      "        78     -353760.0711          +0.0404\n",
      "        79     -353760.0476          +0.0235\n",
      "        80     -353760.0319          +0.0157\n",
      "        81     -353760.0205          +0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        82     -353760.0119          +0.0086\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for cname in class_names:\n",
    "    # convert all vectors to the cluster index\n",
    "    # dataset['one'] = [O^1, ... O^R]\n",
    "    # O^r = (c1, c2, ... ct, ... cT)\n",
    "    # O^r size T x 1\n",
    "    hmm = hmmlearn.hmm.GMMHMM(\n",
    "        n_components=7, n_mix = 2, random_state=42, n_iter=1000, verbose=True,\n",
    "        params='mctw',\n",
    "        init_params='mst',\n",
    "#         startprob_prior = np.array([1., 0., 0., 0., 0., 0., 0.]),\n",
    "#         transmat_prior = transitionMatrix()\n",
    "    )\n",
    "    hmm.startprob_ = np.array([1.0,0.0,0.0,0.0,0.0, 0.0,0.0])\n",
    "    hmm.transmat_ = np.array([\n",
    "            [0.7,0.3,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.7,0.3,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.7,0.3,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.7,0.3,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.7,0.3,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "        ])\n",
    "\n",
    "    X = np.concatenate(dataset_train[cname])\n",
    "    lengths = list([len(x) for x in dataset_train[cname]])\n",
    "#     FOR GMMHMM: NO NEED lengths parameter\n",
    "    hmm.fit(X)\n",
    "    models[cname] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi\n",
      "TRUE PREDICT: 20/20\n",
      "ACCURACY: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nhà\n",
      "TRUE PREDICT: 15/20\n",
      "ACCURACY: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "học\n",
      "TRUE PREDICT: 20/21\n",
      "ACCURACY: 0.9523809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nhân viên\n",
      "TRUE PREDICT: 18/21\n",
      "ACCURACY: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n",
      "Degenerate mixture covariance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hà nội\n",
      "TRUE PREDICT: 20/20\n",
      "ACCURACY: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "for true_cname in class_names:\n",
    "    true_predict = 0\n",
    "#     for O in dataset[true_cname]:\n",
    "    for O in dataset_test[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        predict = max(score, key=score.get)\n",
    "        if predict == true_cname:\n",
    "            true_predict += 1\n",
    "#         print(true_cname, score, predict)\n",
    "    print(true_cname)\n",
    "#     change dataset_test to dataset to test in full dataset\n",
    "    print(f'TRUE PREDICT: {true_predict}/{len(dataset_test[true_cname])}')\n",
    "    print('ACCURACY:', true_predict/len(dataset_test[true_cname]))                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toi': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'song': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'truoc': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'nhan_vien': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'gia_dinh': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "     covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "         [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "     covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     init_params='mst',\n",
       "     means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]],\n",
       " \n",
       "        [[0., 0., ..., 0., 0.],\n",
       "         [0., 0., ..., 0., 0.]]]),\n",
       "     means_weight=array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]),\n",
       "     min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "     random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "     verbose=True,\n",
       "     weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]))}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "toi   89\n",
      "song   92\n",
      "truoc   80\n",
      "nhan_vien   81\n",
      "gia_dinh   79\n",
      "{'toi': 100.0, 'song': 100.0, 'truoc': 100.0, 'nhan_vien': 100.0, 'gia_dinh': 98.75}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "miss = {}\n",
    "acc = {}\n",
    "class_names = [\"toi\", \"song\", \"truoc\", \"nhan_vien\", \"gia_dinh\"]\n",
    "for true_cname in class_names:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "#         print(true_cname, score, pre)\n",
    "        if pre == true_cname:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyentiendat/anaconda3/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gia_dinh'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = get_mfcc('data.wav')\n",
    "score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "inverse = [(value, key) for key, value in score.items()]\n",
    "predict = max(inverse)[1]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test_toi dataset\n",
      "vectors (895, 36)\n",
      "Testing\n",
      "test_toi {'toi': -7620.212225111643, 'song': -8230.521415545485, 'truoc': -8144.95941912607, 'nhan_vien': -8055.198681860034, 'gia_dinh': -8394.809761647619} toi\n",
      "test_toi {'toi': -2149.219995999329, 'song': -2412.9368211004685, 'truoc': -2362.355993332991, 'nhan_vien': -2303.6970214219964, 'gia_dinh': -2363.120670330845} toi\n",
      "test_toi {'toi': -4754.502610596342, 'song': -5116.315693293601, 'truoc': -5357.214125396858, 'nhan_vien': -5237.692756976712, 'gia_dinh': -4976.711196599017} toi\n",
      "test_toi {'toi': -1351.7292054794661, 'song': -1544.0518867550961, 'truoc': -1376.3849420262004, 'nhan_vien': -1426.545629349316, 'gia_dinh': -1475.5824434061235} toi\n",
      "test_toi {'toi': -2143.280006319747, 'song': -2328.4712382758908, 'truoc': -2223.3070208305335, 'nhan_vien': -2233.811970473114, 'gia_dinh': -2324.3715712918483} toi\n",
      "test_toi {'toi': -8820.564295791386, 'song': -9605.533709422523, 'truoc': -10004.417025004443, 'nhan_vien': -9616.831028032006, 'gia_dinh': -9375.206622770245} toi\n",
      "test_toi {'toi': -2069.5594524985504, 'song': -2242.3621953738175, 'truoc': -2212.2188260951916, 'nhan_vien': -2168.5605912476267, 'gia_dinh': -2280.2997491272645} toi\n",
      "test_toi {'toi': -1648.5222531713205, 'song': -1848.7494146082252, 'truoc': -1811.1386310755595, 'nhan_vien': -1775.2110488377677, 'gia_dinh': -1809.327739840239} toi\n",
      "test_toi {'toi': -11197.267099110528, 'song': -12506.81858905508, 'truoc': -12452.505117404919, 'nhan_vien': -12336.443860250385, 'gia_dinh': -12673.002387402235} toi\n",
      "test_toi {'toi': -3578.380490444765, 'song': -3687.392706508314, 'truoc': -3807.6792808771797, 'nhan_vien': -3604.1534383127887, 'gia_dinh': -3687.1969087526713} toi\n",
      "test_toi {'toi': -1660.1329564515217, 'song': -1787.282081670068, 'truoc': -1729.5932580958008, 'nhan_vien': -1725.2274217772508, 'gia_dinh': -1660.4557980246436} toi\n",
      "test_toi {'toi': -1965.4204392352544, 'song': -2192.2286103568154, 'truoc': -2180.344916623294, 'nhan_vien': -2150.5131991189965, 'gia_dinh': -2194.751003454861} toi\n",
      "test_toi {'toi': -2872.6013775332067, 'song': -3101.5967029959556, 'truoc': -3139.5279724399243, 'nhan_vien': -3084.2568805620344, 'gia_dinh': -3131.8406339020194} toi\n",
      "test_toi {'toi': -3141.133185969157, 'song': -3485.322137102206, 'truoc': -3425.9128291143825, 'nhan_vien': -3264.497107634756, 'gia_dinh': -3417.420818533449} toi\n",
      "test_toi {'toi': -5987.35172020553, 'song': -6470.820229200312, 'truoc': -6707.664235353807, 'nhan_vien': -6553.3051766719445, 'gia_dinh': -6549.155790545381} toi\n",
      "test_toi {'toi': -2179.252504098013, 'song': -2409.034512792424, 'truoc': -2477.363424350074, 'nhan_vien': -2407.8786648227974, 'gia_dinh': -2477.454439062274} toi\n",
      "test_toi {'toi': -5220.308773905552, 'song': -5610.727159225282, 'truoc': -5484.151265687306, 'nhan_vien': -5366.820821370678, 'gia_dinh': -5464.965975565016} toi\n",
      "test_toi {'toi': -2728.4369285261128, 'song': -2886.119989182102, 'truoc': -2875.944438472844, 'nhan_vien': -2876.0034908249545, 'gia_dinh': -3000.794752973401} toi\n",
      "test_toi {'toi': -6652.918530670467, 'song': -7194.208580314377, 'truoc': -7348.806686690741, 'nhan_vien': -7307.294100885237, 'gia_dinh': -7554.829966276977} toi\n",
      "test_toi {'toi': -3471.632892733901, 'song': -3770.7778292189487, 'truoc': -3681.4537269461403, 'nhan_vien': -3550.5078720265396, 'gia_dinh': -3517.094550167726} toi\n",
      "test_toi   20\n",
      "{'test_toi': 100.0}\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"test_toi\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    \n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "\n",
    "print(\"Testing\")\n",
    "acc = {}\n",
    "test_name = { \"test_toi\"}\n",
    "for true_cname in test_name:\n",
    "    kt = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        pre = max(inverse)[1]\n",
    "        print(true_cname, score, pre)\n",
    "        if pre == true_cname[5:]:\n",
    "            kt +=1\n",
    "    print(true_cname,\" \", kt)\n",
    "    acc[true_cname] = kt * 100 / len(dataset[true_cname])\n",
    "print(acc)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('output1.txt', 'w') as f:\n",
    "#     print(models, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open(\"output1.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "    covars_prior=array([[[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "        [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       "\n",
       "       [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "        [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "        [-1.5, -1.5, ..., -1.5, -1.5]],\n",
       "\n",
       "       [[-1.5, -1.5, ..., -1.5, -1.5],\n",
       "        [-1.5, -1.5, ..., -1.5, -1.5]]]),\n",
       "    covars_weight=array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]]),\n",
       "    init_params='mst',\n",
       "    means_prior=array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]]),\n",
       "    means_weight=array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]]),\n",
       "    min_covar=0.001, n_components=7, n_iter=1000, n_mix=2, params='mctw',\n",
       "    random_state=42, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "    verbose=True,\n",
       "    weights_prior=array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['toi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
